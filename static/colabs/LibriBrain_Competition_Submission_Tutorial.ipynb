{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdEBpx2vchzI"
      },
      "source": [
        "âš ï¸ **Note**: **Submission is currently limited to only the speech detection tasks. We'll be releasing the obfuscated holdout data and an updated submission tutorial for the Phoneme Classification tasks in time for the second half of the competition.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhfbDfTYqMf2"
      },
      "source": [
        "# ðŸ LibriBrain Competition: Submission\n",
        "You've trained a model for one of our tracks and are now ready to submit your results? Congratulations! - let's walk through the process.\n",
        "\n",
        "Broadly, you will need to do the following:\n",
        "1. Run model predictions on our holdout data\n",
        "2. Submit the .CSV file containing your results (find the detailed instructions [here](https://neural-processing-lab.github.io/2025-libribrain-competition/participate/#4-submit-on-evalai)).\n",
        "\n",
        "This tutorial will walk you through step (1), generating the .CSV file for you to submit.\n",
        "\n",
        "In case of any questions or problems, please get in touch through [our Discord server](https://neural-processing-lab.github.io/2025-libribrain-competition/links/discord).\n",
        "\n",
        "âš ï¸ **Note**: We have only comprehensively validated the notebook to work on Colab and Unix. Your experience in other environments (e.g., Windows) may vary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZTwXzPRtP6J"
      },
      "source": [
        "## Setting up dependencies\n",
        "Run the code below *as is*. It will download all required dependencies, including our own [PNPL](https://pypi.org/project/pnpl/) package. On Windows, you might have to restart your Kernel after the installation has finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WXzSJx9srGY"
      },
      "outputs": [],
      "source": [
        "# Install additional dependencies\n",
        "%pip install -q lightning torchmetrics scikit-learn plotly ipywidgets tqdm pnpl\n",
        "\n",
        "# Set up base path for dataset and related files (base_path is assumed to be set in the cells below!)\n",
        "base_path = \"./libribrain\"\n",
        "try:\n",
        "    import google.colab  # This module is only available in Colab.\n",
        "    in_colab = True\n",
        "    base_path = \"/content\"  # This is the folder displayed in the Colab sidebar\n",
        "except ImportError:\n",
        "    in_colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXJlK9ZhpUjM"
      },
      "source": [
        "## Generating submission CSV\n",
        "For the speech detection task, you will be asked to evaluate **for each timepoint** of the \"competition holdout\" split of the data if it is speech or not - this means we expect a total of 560,638 predictions (that is how many samples there are in that split). These predictions should then be packaged into a .csv file you can upload on EvalAI. As we don't have labels to train against, the way you download the holdout data differs slightly from the regular `LibriBrainSpeech` dataset.\n",
        "\n",
        "Here is how to generate the submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TePs7dQRCbVd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from pnpl.datasets import LibriBrainCompetitionHoldout\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# First, instantiate the Competition Holdout dataset\n",
        "speech_holdout_dataset = LibriBrainCompetitionHoldout(\n",
        "    data_path=base_path,  # Same as in the other LibriBrain dataset - this is where we'll store the data\n",
        "    tmax=0.8,             # Also identical to the other datasets - how many samples to return/group together\n",
        "    task=\"speech\"         # \"speech\" or \"phoneme\" (\"phoneme\" is not supported until Phoneme track launch)\n",
        ")\n",
        "\n",
        "# Next, create a DataLoader for the dataset\n",
        "dataloader = DataLoader(\n",
        "    speech_holdout_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# The final array of predictions must contain len(speech_holdout_dataset) values between 0..1\n",
        "segments_to_predict = len(speech_holdout_dataset)\n",
        "print(segments_to_predict)\n",
        "\n",
        "# Finally, we loop over every sample to generate a prediction.\n",
        "# For now, we will fill the submission with random values\n",
        "all_random = torch.rand((segments_to_predict, 1))\n",
        "random_predictions = [None] * segments_to_predict\n",
        "\n",
        "for i, sample in enumerate(tqdm(dataloader)):\n",
        "    # For your submission, this is where you would generate your model prediction:\n",
        "    # segment = sample[0]                  # The actual segment data is at sample[0]\n",
        "    # prediction = model.predict(segment)  # Assuming model has a predict method\n",
        "    #\n",
        "    # Here, we simply pull the precomputed random tensor instead\n",
        "    random_predictions[i] = all_random[i]\n",
        "\n",
        "speech_holdout_dataset.generate_submission_in_csv(\n",
        "    random_predictions,\n",
        "    \"holdout_speech_predictions.csv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeNyLjZWEyFS"
      },
      "source": [
        "If you don't wish to wait the ~20min it takes to generate the file above, you can generate a mock (valid, but filled with random values) submission file without iterating over all samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2fpYCXLExb6"
      },
      "outputs": [],
      "source": [
        "from pnpl.datasets import LibriBrainCompetitionHoldout\n",
        "import torch\n",
        "\n",
        "\n",
        "speech_holdout_dataset = LibriBrainCompetitionHoldout(\n",
        "    data_path=base_path,\n",
        "    tmax=0.8,\n",
        "    task=\"speech\"\n",
        ")\n",
        "\n",
        "segments_to_predict = len(speech_holdout_dataset)\n",
        "all_random = torch.rand((segments_to_predict, 1))  # build all (1,) tensors at once\n",
        "random_predictions = list(all_random)              # convert to list of shape-(1,) tensors\n",
        "speech_holdout_dataset.generate_submission_in_csv(\n",
        "    random_predictions,\n",
        "    \"holdout_speech_predictions.csv\"\n",
        ")\n",
        "print(\"Submission file created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiaqfLF3med8"
      },
      "source": [
        "### Generating the correct number of predictions\n",
        "The code above is all you need to generate your submission! Below, we will outline some more details that may be helpful to consider. \n",
        "\n",
        "We understand that while training your model, you may have played around with averaging samples, combining multiple timepoints into a singular output - in fact, the baseline model used in the [Speech Detection Notebook](https://neural-processing-lab.github.io/2025-libribrain-competition/colabs/LibriBrain_Competition_Speech_Detection.ipynb) did just that. But, for the submission to be valid, it will need to contain 560,638 predictions - one per timepoint. There are multiple ways to resolve this (predicting a baseline value if no prediction can be performed, interpolating between results,...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we will show one workaround. As our baseline model was trained to predict a single label for each sample of 200 timepoints, we need to somehow deal with the first and last 100 timepoints:\n",
        "\n",
        "![Padding due to Sliding Window](https://neural-processing-lab.github.io/2025-libribrain-competition/images/baseline-model-sliding-window-padding.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Follow along as we:\n",
        "1. Load a trained speech detection model\n",
        "2. Handle the problematic samples in the holdout dataset that can't be loaded/used as they don't contain sufficient timepoints\n",
        "3. Generate exactly 560,638 predictions (as required for a valid submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 1: Define the model architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import lightning as L\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torchmetrics\n",
        "from sklearn.metrics import roc_curve, auc, balanced_accuracy_score, jaccard_score\n",
        "from torchmetrics import Precision, Recall, F1Score\n",
        "from lightning.pytorch.callbacks import Callback\n",
        "import numpy as np\n",
        "from torchmetrics.functional import recall\n",
        "\n",
        "# Model architecture (identical to Speech Detection Colab tutorial)\n",
        "class SpeechModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        input_dim (int): Number of channels/features in the input tensor (usually SENSORS_SPEECH_MASK)\n",
        "        model_dim (int): Dimensionality for the intermediate model representation.\n",
        "        dropout_rate (float, optional): Dropout probability applied after convolutional and LSTM layers.\n",
        "        lstm_layers (int, optional): Number of layers in the LSTM module.\n",
        "        bi_directional (bool, optional): If True, uses a bidirectional LSTM; otherwise, a unidirectional LSTM.\n",
        "        batch_norm (bool, optional): Indicates whether to use batch normalization.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, model_dim, dropout_rate=0.3, lstm_layers = 1, bi_directional = False, batch_norm=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=input_dim,\n",
        "            out_channels=model_dim,\n",
        "            kernel_size=3,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=model_dim) if batch_norm else nn.Identity()\n",
        "        self.conv_dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=model_dim,\n",
        "            hidden_size=model_dim,\n",
        "            num_layers=self.lstm_layers,\n",
        "            dropout=dropout_rate,\n",
        "            batch_first=True,\n",
        "            bidirectional=bi_directional\n",
        "        )\n",
        "        self.lstm_dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.speech_classifier = nn.Linear(model_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.conv_dropout(x)\n",
        "        # LSTM expects (batch, seq_len, input_size)\n",
        "        output, (h_n, c_n) = self.lstm(x.permute(0, 2, 1))\n",
        "        last_layer_h_n = h_n\n",
        "        if self.lstm_layers > 1:\n",
        "            # handle more than one layer\n",
        "            last_layer_h_n = h_n[-1, :, :]\n",
        "            last_layer_h_n = last_layer_h_n.unsqueeze(0)\n",
        "        output = self.lstm_dropout(last_layer_h_n)\n",
        "        output = output.flatten(start_dim=0, end_dim=1)\n",
        "        x = self.speech_classifier(output)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BCEWithLogitsLossWithSmoothing(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, pos_weight = 1.0):\n",
        "        \"\"\"\n",
        "        Binary Cross-Entropy Loss with Deterministic Label Smoothing.\n",
        "\n",
        "        Parameters:\n",
        "            smoothing (float): Smoothing factor. Must be between 0 and 1.\n",
        "            pos_weight (float): Weight for the positive class.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]))\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        target = target.float()  # Ensure target is a float tensor\n",
        "        target_smoothed = target * (1 - self.smoothing) + self.smoothing * 0.5\n",
        "        return self.bce_loss(logits, target_smoothed)\n",
        "\n",
        "\n",
        "class SpeechClassifier(L.LightningModule):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        input_dim (int): Number of input channels/features. This is passed to the underlying SpeechModel.\n",
        "        model_dim (int): Dimensionality of the intermediate model representation.\n",
        "        learning_rate (float, optional): Learning rate for the optimizer.\n",
        "        weight_decay (float, optional): Weight decay for the optimizer.\n",
        "        batch_size (int, optional): Batch size used during training and evaluation.\n",
        "        dropout_rate (float, optional): Dropout probability applied after convolutional and LSTM layers.\n",
        "        smoothing (float, optional): Label smoothing factor applied in the BCEWithLogits loss.\n",
        "        pos_weight (float, optional): Weight for the positive class in the BCEWithLogits loss.\n",
        "        batch_norm (bool, optional): Indicates whether to use batch normalization.\n",
        "        lstm_layers (int, optional): Number of layers in the LSTM module within the SpeechModel.\n",
        "        bi_directional (bool, optional): If True, uses a bidirectional LSTM in the SpeechModel; otherwise, uses a unidirectional LSTM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, model_dim, learning_rate=1e-3, weight_decay=0.01, batch_size=32, dropout_rate=0.3, smoothing=0.1, pos_weight = 1.0 , batch_norm = False, lstm_layers = 1, bi_directional = False):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.batch_size = batch_size\n",
        "        self.model = SpeechModel(input_dim, model_dim, dropout_rate=dropout_rate, lstm_layers=lstm_layers, bi_directional=bi_directional, batch_norm=batch_norm)\n",
        "\n",
        "        self.loss_fn = BCEWithLogitsLossWithSmoothing(smoothing=smoothing, pos_weight = pos_weight)\n",
        "\n",
        "        self.val_step_outputs = []\n",
        "        self.test_step_outputs = {}\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "    def _shared_eval_step(self, batch, stage):\n",
        "        x = batch[0]\n",
        "        y = batch[1] # (batch, seq_len)\n",
        "\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "        y_probs = probs.detach().cpu()\n",
        "\n",
        "        y_true = batch[1].detach().cpu()\n",
        "        meg = x.detach().cpu()\n",
        "\n",
        "        self.log(f'{stage}_loss', loss, on_step=False, on_epoch=True, batch_size=self.batch_size)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._shared_eval_step(batch, \"train\")\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._shared_eval_step(batch, \"val\")\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x = batch[0]\n",
        "        y = batch[1]  # (batch, seq_len)\n",
        "\n",
        "        # ugly, taking care of only one label\n",
        "        if len(y.shape) != 1:\n",
        "            y = y.flatten(start_dim=0, end_dim=1).view(-1, 1)  # (batch, seq_len) -> (batch * seq_len, 1)\n",
        "        else:\n",
        "            y = y.unsqueeze(1)\n",
        "\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Append data to the defaultdict\n",
        "        # Ensure keys exist before appending\n",
        "        if \"y_probs\" not in self.test_step_outputs:\n",
        "            self.test_step_outputs[\"y_probs\"] = []\n",
        "        if \"y_true\" not in self.test_step_outputs:\n",
        "            self.test_step_outputs[\"y_true\"] = []\n",
        "        if \"meg\" not in self.test_step_outputs:\n",
        "            self.test_step_outputs[\"meg\"] = []\n",
        "\n",
        "        # Append data\n",
        "        if y.shape[-1] != 1:\n",
        "            self.test_step_outputs[\"y_probs\"].extend(\n",
        "                probs.detach().view(x.shape[0], x.shape[-1]).cpu())  # (batch, seq_len)\n",
        "        else:\n",
        "            self.test_step_outputs[\"y_probs\"].extend(\n",
        "                probs.detach().view(x.shape[0], 1).cpu())  # (batch, seq_len)\n",
        "\n",
        "        self.test_step_outputs[\"y_true\"].extend(batch[1].detach().cpu())  # (batch, seq_len)\n",
        "        self.test_step_outputs[\"meg\"].extend(x.detach().cpu())  # MEG data (batch, channels, seq_len)\n",
        "\n",
        "        return self._shared_eval_step(batch, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 2: Load trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "# Load trained model checkpoint\n",
        "checkpoint_path = f\"{base_path}/speech_model.ckpt\"\n",
        "\n",
        "# Download model if it doesn't exist\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"Downloading model to {checkpoint_path}\")\n",
        "    url = \"https://neural-processing-lab.github.io/2025-libribrain-competition/speech_model.ckpt\"\n",
        "    urllib.request.urlretrieve(url, checkpoint_path)\n",
        "    print(\"Model downloaded successfully!\")\n",
        "\n",
        "# These are the sensor mask used in the model checkpoint\n",
        "SENSORS_SPEECH_MASK = [18, 20, 22, 23, 45, 120, 138, 140, 142, 143, 145,\n",
        "                       146, 147, 149, 175, 176, 177, 179, 180, 198, 271, 272, 275]\n",
        "\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Loading trained model from {checkpoint_path}\")\n",
        "        \n",
        "    # Load the trained model with parameters matching the checkpoint\n",
        "    model = SpeechClassifier.load_from_checkpoint(\n",
        "        checkpoint_path,\n",
        "        input_dim=len(SENSORS_SPEECH_MASK),  # 23 sensors\n",
        "        model_dim=100,  # The checkpoint uses 100 dimensions, not 64\n",
        "        learning_rate=1e-3,\n",
        "        weight_decay=0.01,\n",
        "        batch_size=32,\n",
        "        dropout_rate=0.3,\n",
        "        smoothing=0.1,\n",
        "        pos_weight=1.0,\n",
        "        batch_norm=False,  # No batch norm in the checkpoint\n",
        "        lstm_layers=2,  # The checkpoint has 2 LSTM layers\n",
        "        bi_directional=False\n",
        "    )\n",
        "    model.eval()  # Set to evaluation mode\n",
        "        \n",
        "    print(\"Model loaded successfully!\")\n",
        "    print(f\"Model uses {len(SENSORS_SPEECH_MASK)} sensors out of 306\")\n",
        "        \n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model has {total_params:,} parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 3: Create a wrapper to handle problematic samples**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pnpl.datasets import LibriBrainCompetitionHoldout\n",
        "\n",
        "class SimpleHoldoutWrapper(Dataset):\n",
        "    \"\"\"\n",
        "    Simple wrapper that categorizes samples as full vs incomplete.\n",
        "    \"\"\"\n",
        "    def __init__(self, holdout_dataset):\n",
        "        self.holdout_dataset = holdout_dataset\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.holdout_dataset)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            sample = self.holdout_dataset[idx]\n",
        "            meg_data = sample[0]  # Shape: [306, timepoints]\n",
        "            \n",
        "            if meg_data.shape[1] == 200:\n",
        "                return meg_data, \"full\"  # Full sample - use model\n",
        "            else:\n",
        "                return meg_data, \"incomplete\"  # Incomplete - use default\n",
        "                \n",
        "        except Exception as e:\n",
        "            return None, \"error\"\n",
        "\n",
        "# Create the holdout dataset\n",
        "holdout_dataset = LibriBrainCompetitionHoldout(\n",
        "    data_path=base_path,\n",
        "    tmax=0.8,\n",
        "    task=\"speech\"\n",
        ")\n",
        "\n",
        "print(f\"Holdout dataset loaded with {len(holdout_dataset):,} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 4: Generate predictions efficiently**\n",
        "\n",
        "Technically, we could now loop over every sample and check if it contains the correct number of timepoints. However, this is very slow and we already know that only the final 200 samples will contain less than 200 timepoints (and therefore be incomplete):\n",
        "\n",
        "![Sample Structure](https://neural-processing-lab.github.io/2025-libribrain-competition/images/libribrain-speech-holdout-sample-structure.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_predictions(model, holdout_dataset):\n",
        "    \"\"\"\n",
        "    Sliding window prediction generation:\n",
        "    - Creates 200-timepoint windows to predict the middle timepoint\n",
        "    - First 99 timepoints (0-98): default to 1 (speech) - no previous context\n",
        "    - Last 100 timepoints: default to 1 (speech) - no future context  \n",
        "    - Middle timepoints 99-560537: use model predictions\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the total number of timepoints in the dataset\n",
        "    total_timepoints = len(holdout_dataset)\n",
        "    print(f\"Total timepoints in dataset: {total_timepoints:,}\")\n",
        "    \n",
        "    # Calculate prediction windows\n",
        "    window_size = 200\n",
        "    half_window = window_size // 2  # 100\n",
        "    \n",
        "    # Timepoints we can predict (have full 200-point context)\n",
        "    first_predictable = half_window - 1  # 99 (first model prediction is for timepoint 99)\n",
        "    last_predictable = total_timepoints - half_window - 1  # 560537\n",
        "    predictable_count = last_predictable - first_predictable + 1  # 560439\n",
        "    \n",
        "    print(f\"\\nSliding window analysis:\")\n",
        "    print(f\"  Window size: {window_size} timepoints\")\n",
        "    print(f\"  First {first_predictable + 1} timepoints (0-{first_predictable}): default to speech (no past context)\")\n",
        "    print(f\"  Timepoints {first_predictable}-{last_predictable}: {predictable_count:,} model predictions\")\n",
        "    print(f\"  Last {half_window} timepoints: default to speech (no future context)\")\n",
        "    print(f\"  Total predictions needed: {total_timepoints:,}\")\n",
        "    \n",
        "    # Initialize predictions array\n",
        "    all_predictions = [None] * total_timepoints\n",
        "    \n",
        "    # Step 1: Fill first 99 timepoints with default predictions (timepoints 0-98)\n",
        "    print(f\"\\nSetting first {first_predictable + 1} timepoints (0-{first_predictable}) to speech=1...\")\n",
        "    for i in range(first_predictable + 1):\n",
        "        all_predictions[i] = 1.0\n",
        "    \n",
        "    # Step 2: Fill last 100 timepoints with default predictions  \n",
        "    print(f\"Setting last {half_window} timepoints to speech=1...\")\n",
        "    for i in range(last_predictable + 1, total_timepoints):\n",
        "        all_predictions[i] = 1.0\n",
        "    \n",
        "    # Step 3: Generate model predictions for the middle timepoints\n",
        "    print(f\"\\nGenerating model predictions for {predictable_count:,} timepoints...\")\n",
        "    \n",
        "\n",
        "    model.eval()\n",
        "    batch_size = 1000  # Process predictions in batches\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for start_idx in tqdm(range(0, predictable_count, batch_size), desc=\"Model predictions\"):\n",
        "            end_idx = min(start_idx + batch_size, predictable_count)\n",
        "            \n",
        "            # For each timepoint in this batch, find the corresponding dataset sample\n",
        "            batch_data = []\n",
        "            batch_timepoints = []\n",
        "            \n",
        "            for batch_pos in range(start_idx, end_idx):\n",
        "                timepoint_idx = first_predictable + batch_pos  # Actual timepoint index (99, 100, ...)\n",
        "                \n",
        "                # The dataset sample that has timepoint_idx as its center (at position 99)\n",
        "                # If timepoint_idx is the center, then the window starts at timepoint_idx - 99\n",
        "                window_start = timepoint_idx - (half_window - 1)  # timepoint_idx - 99\n",
        "                dataset_sample_idx = window_start  # This dataset sample starts at window_start\n",
        "                \n",
        "                try:\n",
        "                    # Ensure we don't go out of bounds\n",
        "                    if 0 <= dataset_sample_idx < len(holdout_dataset):\n",
        "                        sample = holdout_dataset[dataset_sample_idx]\n",
        "                        meg_data = sample[0]  # [306, 200]\n",
        "                        \n",
        "                        # Verify this sample has the right timepoints\n",
        "                        if meg_data.shape[1] == window_size:\n",
        "                            batch_data.append(meg_data)\n",
        "                            batch_timepoints.append(timepoint_idx)\n",
        "                        else:\n",
        "                            # If not full window, default to speech\n",
        "                            all_predictions[timepoint_idx] = 1.0\n",
        "                    else:\n",
        "                        # Out of bounds, default to speech\n",
        "                        all_predictions[timepoint_idx] = 1.0\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    # If anything fails, default to speech\n",
        "                    all_predictions[timepoint_idx] = 1.0\n",
        "                    if start_idx == 0 and len([p for p in all_predictions[:timepoint_idx+1] if p == 1.0]) <= 5:\n",
        "                        print(f\"    Timepoint {timepoint_idx} failed: {str(e)[:100]}...\")\n",
        "            \n",
        "            # Process batch with model if we have data\n",
        "            if batch_data:\n",
        "                try:\n",
        "                    # Stack into batch and apply sensor mask\n",
        "                    meg_batch = torch.stack(batch_data)  # [batch, 306, 200]\n",
        "                    meg_masked = meg_batch[:, SENSORS_SPEECH_MASK, :]  # [batch, 23, 200]\n",
        "                    \n",
        "                    # Get model predictions\n",
        "                    logits = model(meg_masked)\n",
        "                    probs = torch.sigmoid(logits).squeeze()\n",
        "                    \n",
        "                    if probs.dim() == 0:\n",
        "                        probs = probs.unsqueeze(0)\n",
        "                    \n",
        "                    # Store predictions\n",
        "                    prob_list = probs.cpu().tolist()\n",
        "                    for i, prob in enumerate(prob_list):\n",
        "                        if i < len(batch_timepoints):\n",
        "                            timepoint_idx = batch_timepoints[i]\n",
        "                            all_predictions[timepoint_idx] = prob\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"Model failed on batch {start_idx // batch_size}: {e}\")\n",
        "                    # If model fails, use default for all timepoints in batch\n",
        "                    for timepoint_idx in batch_timepoints:\n",
        "                        all_predictions[timepoint_idx] = 1.0\n",
        "            \n",
        "            # Fill any unfilled timepoints in this batch with default\n",
        "            for batch_pos in range(start_idx, end_idx):\n",
        "                timepoint_idx = first_predictable + batch_pos\n",
        "                if all_predictions[timepoint_idx] is None:\n",
        "                    all_predictions[timepoint_idx] = 1.0\n",
        "    \n",
        "    # Verify all predictions are filled\n",
        "    for i, pred in enumerate(all_predictions):\n",
        "        if pred is None:\n",
        "            all_predictions[i] = 1.0\n",
        "    \n",
        "    print(f\"\\nGenerated {len(all_predictions):,} predictions\")\n",
        "    \n",
        "    # Summary statistics\n",
        "    default_start_count = first_predictable\n",
        "    default_end_count = half_window  \n",
        "    model_preds = [all_predictions[i] for i in range(first_predictable, last_predictable + 1) \n",
        "                   if abs(all_predictions[i] - 1.0) > 1e-6]\n",
        "    \n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"  Default predictions (start): {default_start_count:,} (all 1.0)\")\n",
        "    print(f\"  Model predictions: {len(model_preds):,} (avg: {sum(model_preds)/len(model_preds):.3f})\" if model_preds else \"  Model predictions: 0\")\n",
        "    print(f\"  Default predictions (end): {default_end_count:,} (all 1.0)\")\n",
        "            \n",
        "    return all_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 5: Generate the final submission**\n",
        "The model is trained to predict the **middle timepoint** of a 200-timepoint window. With 560,638 total timepoints, you can create a sliding window where (zero-indexed):\n",
        "\n",
        "- **Timepoints 0-98:** Cannot predict (need 100 previous timepoints) â†’ Default to speech (1.0)\n",
        "- **Timepoints 99-560,537:** Can predict using model (560,439 predictions) \n",
        "- **Timepoints 560,538-560,637:** Cannot predict (need 100 future timepoints) â†’ Default to speech (1.0)\n",
        "\n",
        "Now let's run the prediction generation and create the submission CSV file:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "predictions = generate_predictions(model, holdout_dataset)\n",
        "\n",
        "# Convert to tensor format expected by submission function\n",
        "tensor_predictions = [torch.tensor(pred).unsqueeze(0) for pred in predictions]\n",
        "\n",
        "# Generate submission CSV\n",
        "submission_filename = \"submission.csv\"\n",
        "holdout_dataset.generate_submission_in_csv(tensor_predictions, submission_filename)\n",
        "\n",
        "print(f\"âœ… SUCCESS! Submission file created: {submission_filename}\")\n",
        "print(f\"ðŸ“„ Contains {len(predictions):,} predictions\")\n",
        "print(\"ðŸŽ¯ Ready for upload to EvalAI!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Done! - we have now used to model from the Colab Tutorial to generate predictions for 560,438 out of 560638 timepoints, and padded the first and last 100 with a fixed majority class prediction to ensure we always end up with the expected amount of predictions for the submission!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ready to submit?\n",
        "After generating the predictions file, the next step is to submit it for evaluation. Don't worry, you are allowed to submit multiple times. Please, take a look at the [Submit on EvalAI](https://neural-processing-lab.github.io/2025-libribrain-competition/participate/#4-submit-on-evalai) section on the website to learn more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDGZ8LLzAMvb"
      },
      "source": [
        "## That's it! ðŸ¥³\n",
        "Thanks for taking the time to look at and/or participate in our competition. If this caught your interest, you might also want to take a look at the more advanced version of the task, focussed on Phoneme Classification - you can find the corresponding Colab [here](https://neural-processing-lab.github.io/2025-libribrain-competition/links/phoneme-colab). If you have any open questions, please get in touch through [our Discord server](https://neural-processing-lab.github.io/2025-libribrain-competition/links/discord)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
