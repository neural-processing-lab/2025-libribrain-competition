{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBdHU3xXe3xY"
      },
      "source": [
        "# üçç LibriBrain Competition: Advanced (Phoneme Classification)\n",
        "Welcome! This Colab is the starting point for the second track of the [LibriBrain competition](https://libribrain.com/) hosted by the [PNPL](pnpl.robots.ox.ac.uk/) at NeurIPS 2025. For a more basic introduction, you might prefer to take a look at the [Speech Detection variant](https://neural-processing-lab.github.io/2025-libribrain-competition/links/speech-colab) first, which includes a more comprehensive introduction and a slightly simpler task.\n",
        "\n",
        "The following notebook will walk you through\n",
        "1. setting up all necessary dependencies,\n",
        "2. downloading training data, and\n",
        "3. training a minimal model\n",
        "\n",
        "It is fully functional in the Colab Free Tier, though training will of course be faster with more GPU horsepower. With default settings on a `T4` instance, the main training run should take no more than 45 minutes. If you want to speed up model training, make sure you are on a GPU runtime by clicking Runtime -> Change runtime type. TPU acceleration is currently not supported.\n",
        "\n",
        "In case of any questions or problems, please get in touch through [our Discord server](https://neural-processing-lab.github.io/2025-libribrain-competition/links/discord).\n",
        "\n",
        "‚ö†Ô∏è **Note**: We have only comprehensively validated the notebook to work on Colab and Unix. Your experience in other environments (e.g., Windows) may vary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su09-lYagdyt"
      },
      "source": [
        "## Setting up dependencies\n",
        "Run the code below *as is*. It will download all required dependencies, including our own [PNPL](https://pypi.org/project/pnpl/) package. On Windows, you might have to restart your Kernel after the installation has finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF9GYq1rYGQ5"
      },
      "outputs": [],
      "source": [
        "# Install additional dependencies\n",
        "%pip install -q mne_bids lightning torchmetrics scikit-learn plotly ipywidgets pnpl\n",
        "\n",
        "# Set up base path for dataset and related files (base_path is assumed to be set in the cells below!)\n",
        "base_path = \"./libribrain\"\n",
        "try:\n",
        "    import google.colab  # This module is only available in Colab.\n",
        "    in_colab = True\n",
        "    base_path = \"/content\"  # This is the folder displayed in the Colab sidebar\n",
        "except ImportError:\n",
        "    in_colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6AWehcygrCg"
      },
      "source": [
        "## Preparing the dataset\n",
        "The code below will automatically download the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m0Z05HnYKp3"
      },
      "outputs": [],
      "source": [
        "from pnpl.datasets import LibriBrainPhoneme\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "train_dataset = LibriBrainPhoneme(\n",
        "  data_path=f\"{base_path}/data/\",\n",
        "  include_run_keys = [(\"0\",str(i),\"Sherlock1\",\"1\") for i in range(1, 11)],\n",
        "  tmin=0.0,\n",
        "  tmax = 0.5,\n",
        "  preload_files = True\n",
        "  )\n",
        "\n",
        "channel_means = train_dataset.channel_means\n",
        "channel_stds = train_dataset.channel_stds\n",
        "\n",
        "\n",
        "val_dataset = LibriBrainPhoneme(\n",
        "  data_path=f\"{base_path}/data/\",\n",
        "  include_run_keys = [['0', '11', 'Sherlock1', '2'], ['0', '12', 'Sherlock1', '2']],\n",
        "  standardize=True,\n",
        "  tmin=0.0,\n",
        "  tmax = 0.5,\n",
        "  preload_files = True\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g79wqtgQWaj9"
      },
      "source": [
        "## Signal averaging the training data\n",
        "While we could now train our model with the above dataloaders, the signal-to-noise ratio of a single datapoint turns out to be very low. Therefore, we average the signals of multiple instances of the same phoneme in the training data to filter out some of the noise. This is called [signal averaging](https://en.wikipedia.org/wiki/Signal_averaging)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PShBXiGyFHcE"
      },
      "outputs": [],
      "source": [
        "from pnpl.datasets import GroupedDataset\n",
        "\n",
        "averaged_train_dataset = GroupedDataset(train_dataset, grouped_samples = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSTwRyOFgx6P"
      },
      "source": [
        "## Defining the model\n",
        "This is the model architecture we'll use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjSoKxIWYBSV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import lightning as L\n",
        "from torch import nn\n",
        "from torchmetrics import F1Score\n",
        "\n",
        "# Basic LightningModule\n",
        "class PhonemeClassificationModel(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(306, 128, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16000, 39)\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.f1_macro = F1Score(num_classes=39, average='macro', task=\"multiclass\")\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        f1_macro = self.f1_macro(y_hat, y)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_f1_macro', f1_macro)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        f1_macro = self.f1_macro(y_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_f1_macro', f1_macro, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.model.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAMl25Lpg3Ak"
      },
      "source": [
        "## Actually training\n",
        "The code below will train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7keM-qrpYBSW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L\n",
        "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
        "\n",
        "# Setup paths for logs and checkpoints\n",
        "LOG_DIR = f\"{base_path}/lightning_logs\"\n",
        "CHECKPOINT_PATH = f\"{base_path}/models/phoneme_model.ckpt\"\n",
        "\n",
        "# Minimal logging setup\n",
        "logger = CSVLogger(\n",
        "    save_dir=LOG_DIR,\n",
        "    name=\"\",\n",
        "    version=None,\n",
        ")\n",
        "if in_colab:  # In Colab, we use the built-in Tensorboard setup\n",
        "    logger = TensorBoardLogger(\n",
        "        save_dir=LOG_DIR,\n",
        "        name=\"\",\n",
        "        version=None,\n",
        "        default_hp_metric=True\n",
        "    )\n",
        "    if not os.path.exists(LOG_DIR):\n",
        "        os.makedirs(LOG_DIR)\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir $LOG_DIR\n",
        "\n",
        "# Set a fixed seed for reproducibility\n",
        "L.seed_everything(42)\n",
        "\n",
        "# Conditionally set num_workers to avoid multiprocessing issues (try increasing if performance is problematic)\n",
        "num_workers = 2 if in_colab else 0\n",
        "\n",
        "# Configure data loaders\n",
        "train_dataloader = DataLoader(averaged_train_dataset, batch_size=16, shuffle=True, num_workers=num_workers)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Initialize the PhonemeClassificationModel model\n",
        "model = PhonemeClassificationModel()\n",
        "\n",
        "# Log Hyperparameters (these will be empty be default!)\n",
        "logger.log_hyperparams(model.hparams)\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = L.Trainer(\n",
        "    devices=\"auto\",\n",
        "    max_epochs=15,\n",
        "    logger=logger,\n",
        "    enable_checkpointing=True,\n",
        ")\n",
        "\n",
        "# Actually train the model\n",
        "trainer.fit(model, train_dataloader, val_dataloader)\n",
        "\n",
        "# Save the trained model\n",
        "trainer.save_checkpoint(CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-aAOoAog74h"
      },
      "source": [
        "## Validating our results\n",
        "Let's look at how our model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7GLTlBeYBSW"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import F1Score\n",
        "\n",
        "def validate(val_loader, module, labels):\n",
        "    disp_labels = labels\n",
        "    module.eval()\n",
        "    predicted_phonemes = []\n",
        "    true_phonemes = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x, y = batch\n",
        "            x = x.to(module.device)\n",
        "            y = y.to(module.device)\n",
        "            outputs = module(x)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            predicted_phonemes.extend(preds)\n",
        "            true_phonemes.extend(y)\n",
        "\n",
        "    true_phonemes = torch.stack(true_phonemes)\n",
        "    predicted_phonemes = torch.stack(predicted_phonemes)\n",
        "\n",
        "    f1_macro = F1Score(task=\"multiclass\", average=\"macro\",\n",
        "                       num_classes=len(disp_labels)).to(module.device)\n",
        "\n",
        "    random_preds = torch.randint(\n",
        "        0, len(disp_labels), (len(true_phonemes),), device=module.device)\n",
        "\n",
        "    random_f1_macro = f1_macro(\n",
        "        random_preds, true_phonemes)\n",
        "\n",
        "    f1_macro = f1_macro(predicted_phonemes, true_phonemes)\n",
        "\n",
        "\n",
        "    binary_f1 = F1Score(task=\"binary\").to(module.device)\n",
        "\n",
        "    classes = torch.arange(len(disp_labels))\n",
        "    f1_by_class = []\n",
        "    random_f1_by_class = []\n",
        "    for c in classes:\n",
        "        class_preds = predicted_phonemes == c\n",
        "        class_targets = true_phonemes == c\n",
        "        class_f1 = binary_f1(class_preds, class_targets)\n",
        "        class_random_preds = random_preds == c\n",
        "        class_random_f1 = binary_f1(class_random_preds, class_targets)\n",
        "\n",
        "        f1_by_class.append(class_f1)\n",
        "        random_f1_by_class.append(class_random_f1)\n",
        "\n",
        "    # We want to return tensors not lists\n",
        "    f1_by_class = torch.stack(f1_by_class)\n",
        "    random_f1_by_class = torch.stack(random_f1_by_class)\n",
        "\n",
        "    return f1_macro, random_f1_macro, f1_by_class, random_f1_by_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsM79Tloi-9m"
      },
      "outputs": [],
      "source": [
        "f1_macro, random_f1_macro, f1_by_class, random_f1_by_class = validate(val_dataloader, model, val_dataset.labels_sorted)\n",
        "print(\"F1 Macro for random predictions: \", random_f1_macro)\n",
        "print(\"F1 Macro for model predictions: \", f1_macro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR9y51Y__se6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.bar(x=(0,1), height=(f1_macro.item(), random_f1_macro.item()), tick_label=(\"Model\", \"Random\"), color=(\"salmon\", \"skyblue\"))\n",
        "plt.title(\"F1 Macro\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w-R0lvBjSxi"
      },
      "source": [
        "Great! We were able to achieve better-than-chance results in terms of F1-Macro and Balanced Accuracy! Let's look at the results for individual classes and see which phonemes we were able to perform well on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeLpVGmWuLRT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def plot_class_specific_scores(scores, random_scores, metric_name, labels, sort=True):\n",
        "\n",
        "    num_classes = len(labels)\n",
        "\n",
        "\n",
        "    # If sorting is requested, reorder the bars based on the criteria.\n",
        "    if sort:\n",
        "        order = torch.argsort(scores).flip(dims=[0])\n",
        "    else:\n",
        "        order = torch.arange(len(scores))\n",
        "\n",
        "    # Reorder the arrays along the class dimension (axis=1) and update the summary statistics\n",
        "    scores = scores[order]\n",
        "    random_scores = random_scores[order]\n",
        "    labels = [labels[i] for i in order]\n",
        "    # Positions of the groups on the x-axis\n",
        "    x = np.arange(num_classes)\n",
        "\n",
        "    # Width of each bar\n",
        "    width = 0.35\n",
        "\n",
        "    # Create a figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(25, 12))\n",
        "\n",
        "    # Plot Random scores bars\n",
        "    bars1 = ax.bar(x - width/2, random_scores, width,\n",
        "                label='Random', capsize=5, color='skyblue', edgecolor='black')\n",
        "\n",
        "    # Plot Actual score bars\n",
        "    bars2 = ax.bar(x + width/2, scores, width,\n",
        "                label='Model', capsize=5, color='salmon', edgecolor='black')\n",
        "\n",
        "    # Add labels and title\n",
        "    ax.set_xlabel('Phonemes', fontsize=16)\n",
        "    ax.set_ylabel(metric_name, fontsize=16)\n",
        "    ax.set_title(metric_name + \" for each Phoneme\", fontsize=20)\n",
        "\n",
        "    # Set x-axis tick labels\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels, rotation=90, fontsize=16)\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend(fontsize=14)\n",
        "\n",
        "    # Add grid for better readability\n",
        "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
        "\n",
        "    # Adjust layout to prevent clipping of tick-labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hEChyB3xGYU"
      },
      "outputs": [],
      "source": [
        "plot_class_specific_scores(scores=f1_by_class, random_scores=random_f1_by_class, metric_name=\"F1\", labels=val_dataset.labels_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk70pXaGhBFW"
      },
      "source": [
        "## That's it! ü•≥\n",
        "You've successfully trained a model that significantly outperforms random guessing in phoneme classification from MEG data - congrats! Thanks for taking the time to look at and/or participate in our competition. If you have any open questions, get in touch on [our Discord server](https://neural-processing-lab.github.io/2025-libribrain-competition/links/discord)!\n",
        "Once you're ready to get your score on the leaderboard, take a look at the [submission tutorial](https://neural-processing-lab.github.io/2025-libribrain-competition/links/submission-colab). You might also want to take another look at the [competition website](https://neural-processing-lab.github.io/2025-libribrain-competition)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
