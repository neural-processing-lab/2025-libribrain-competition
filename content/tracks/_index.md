---
layout: "simple"
---

## Tasks
The **LibriBrain Competition** features two core tasks in decoding language from MEG recordings of brain activity:

- **Speech Detection**  
  Train a model to distinguish *speech* vs. *silence* based on brain activity measured by MEG during a listening session.

<img src="../images/sherlock3.gif" style="width: 550px; height: 350px: cover; border-radius: 8px; display: block; margin: auto;"/>

- **Phoneme Classification**  
  Build a classifier that maps MEG data to the specific **phonemes** being heard.

<img src="../images/sherlock4.gif" style="width: 550px; height: 350px: cover; border-radius: 8px; display: block; margin: auto;"/>

## Tracks

We offer two tracks per task to balance resource constraints with open exploration:

| Track        | Training Data Allowed | Motivation                                              |
|--------------|-----------------------|---------------------------------------------------------|
| **Standard** | LibriBrain only       | Level playing field — innovate on methods/efficiency    |
| **Extended** | Any data              | Embrace scale — see how far teams with resources can go |


Regardless of training data, all tracks will be evaluated on a shared competition holdout set in order to best compare approaches and measure progress.

> You’re welcome to enter any and all tracks. To encourage participation, prize money will be awarded to each team **only once**: if you place in multiple tasks/tracks, then the lower prize you would win rolls down to the next eligible team.

---

We believe these tasks will spark new breakthroughs in language decoding from brain activity. Ready to get started? Check out the [participation guide](../participate)!
